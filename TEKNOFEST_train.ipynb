{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa6a83-3adc-47b0-8ad6-5b9b70462e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow\n",
    "!pip install translate\n",
    "!pip install evaluate\n",
    "!pip install torch\n",
    "!pip install optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1e093e-e4f6-494e-8e9d-6494f032b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from translate import Translator\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f4c699b-919a-43bb-85d5-70f3ea719b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TURKISH DATA IMPORT\n",
    "df = pd.read_csv('teknofest_train_final.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba71d61-d5c0-45ad-98db-53661bd27b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciglilab\\AppData\\Local\\Temp\\ipykernel_2084\\3797106863.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'][i] = str(str(df['is_offensive'][i])+df['target'][i])\n"
     ]
    }
   ],
   "source": [
    "df['labels'] = None\n",
    "for i in range(len(df)):\n",
    "    df['labels'][i] = str(str(df['is_offensive'][i])+df['target'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d83856-865b-4f65-835d-2b2e1deb46dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çürük dişli</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bu adamın islama ve müslümanlara verdiği zarar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erkekler zora gelmez</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Utanmazın götüne kazık sokmuşlar bu tıkırtı ne...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>otomasyon&lt; sistemlerine= doğrudan bağlanabilir</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0                                        çürük dişli     0.0\n",
       "1  Bu adamın islama ve müslümanlara verdiği zarar...     1.0\n",
       "2                               erkekler zora gelmez     2.0\n",
       "3  Utanmazın götüne kazık sokmuşlar bu tıkırtı ne...     3.0\n",
       "4     otomasyon< sistemlerine= doğrudan bağlanabilir     4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = df['labels'].map({\"1INSULT\" : 0,\"1RACIST\" : 1,\"1SEXIST\" : 2,\"1PROFANITY\" : 3,\"0OTHER\" : 4,\"1OTHER\" : 5})\n",
    "df.pop('target')\n",
    "df.pop('is_offensive')\n",
    "df.pop('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7dca5ff-89eb-4e04-8522-e4f20ca0aecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    3544\n",
       "0.0    2407\n",
       "3.0    2386\n",
       "2.0    2099\n",
       "1.0    2054\n",
       "5.0      72\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9780929-358d-4a6e-8482-d3354d95cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.tail(int(len(df)*0.2))\n",
    "df = df.head(int(len(df)*.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fb0b891-5442-4736-a141-7d100b958582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ef89333-ace0-4ded-a829-a22b44d3b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9f4f311-f204-4e2a-b3e8-e199d253d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e62086b0-e3d9-497f-a90a-5b63f511722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 10093\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict(df)\n",
    "test_dataset = Dataset.from_dict(test_df)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fa0c242-7703-48bb-96f4-8f7c1f29fc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10093 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2523\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_datasets = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1a59036-60ba-4510-8f5f-408bb3e803b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
