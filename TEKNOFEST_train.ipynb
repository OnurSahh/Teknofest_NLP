{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa6a83-3adc-47b0-8ad6-5b9b70462e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install tensorflow\n",
    "!pip install translate\n",
    "!pip install evaluate\n",
    "!pip install torch\n",
    "!pip install optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1e093e-e4f6-494e-8e9d-6494f032b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from translate import Translator\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f4c699b-919a-43bb-85d5-70f3ea719b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TURKISH DATA IMPORT\n",
    "df = pd.read_csv('teknofest_train_final.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba71d61-d5c0-45ad-98db-53661bd27b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciglilab\\AppData\\Local\\Temp\\ipykernel_2084\\3797106863.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'][i] = str(str(df['is_offensive'][i])+df['target'][i])\n"
     ]
    }
   ],
   "source": [
    "df['labels'] = None\n",
    "for i in range(len(df)):\n",
    "    df['labels'][i] = str(str(df['is_offensive'][i])+df['target'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d83856-865b-4f65-835d-2b2e1deb46dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çürük dişli</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bu adamın islama ve müslümanlara verdiği zarar...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erkekler zora gelmez</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Utanmazın götüne kazık sokmuşlar bu tıkırtı ne...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>otomasyon&lt; sistemlerine= doğrudan bağlanabilir</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0                                        çürük dişli     0.0\n",
       "1  Bu adamın islama ve müslümanlara verdiği zarar...     1.0\n",
       "2                               erkekler zora gelmez     2.0\n",
       "3  Utanmazın götüne kazık sokmuşlar bu tıkırtı ne...     3.0\n",
       "4     otomasyon< sistemlerine= doğrudan bağlanabilir     4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'] = df['labels'].map({\"1INSULT\" : 0,\"1RACIST\" : 1,\"1SEXIST\" : 2,\"1PROFANITY\" : 3,\"0OTHER\" : 4,\"1OTHER\" : 5})\n",
    "df.pop('target')\n",
    "df.pop('is_offensive')\n",
    "df.pop('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7dca5ff-89eb-4e04-8522-e4f20ca0aecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    3544\n",
       "0.0    2407\n",
       "3.0    2386\n",
       "2.0    2099\n",
       "1.0    2054\n",
       "5.0      72\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9780929-358d-4a6e-8482-d3354d95cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.tail(int(len(df)*0.2))\n",
    "df = df.head(int(len(df)*.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fb0b891-5442-4736-a141-7d100b958582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ef89333-ace0-4ded-a829-a22b44d3b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9f4f311-f204-4e2a-b3e8-e199d253d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e62086b0-e3d9-497f-a90a-5b63f511722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 10093\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict(df)\n",
    "test_dataset = Dataset.from_dict(test_df)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fa0c242-7703-48bb-96f4-8f7c1f29fc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10093 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2523\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_datasets = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1a59036-60ba-4510-8f5f-408bb3e803b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ff4ce7e-9ee3-494c-9613-b5e12bca83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"sentiment_model\", num_labels = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ffd3499-a82b-4997-9e41-2ab5300e6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        num_train_epochs=5,              # total number of training epochs\n",
    "        per_device_train_batch_size=4,   # batch size per device during training\n",
    "        per_device_eval_batch_size=4,    # batch size for evaluation\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='epoch'\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits,labels= eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions= predictions, references = labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,                         # the instantiated Transformers model to be trained\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=tokenized_datasets,    # preprocessed training dataset\n",
    "        eval_dataset = tokenized_test_datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bc13aa5-880a-4753-b0ad-a0ea9f50434e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ciglilab\\AppData\\Local\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='12620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/12620 00:07 < 26:33:37, 0.13 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8de166-e37a-4247-87e5-54e87b5c4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('Sentiment_Model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
